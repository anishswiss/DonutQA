{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from azure.ai.ml import MLClient, command, Output\n",
        "from azure.ai.ml.entities import Environment\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "\n",
        "# Connect to AML workspace\n",
        "ml_client = MLClient.from_config(DefaultAzureCredential())\n",
        "\n",
        "\n",
        "# Define environment\n",
        "donut_env = Environment(\n",
        "    name=\"donut-lora-env\",\n",
        "    image=\"mcr.microsoft.com/azureml/curated/acpt-pytorch-2.0-cuda11.7:latest\",\n",
        "    conda_file=\"environment.yaml\"\n",
        ")\n",
        "\n",
        "# Register environment\n",
        "ml_client.environments.create_or_update(donut_env)\n",
        "\n",
        "\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python train.py --data_dir ./data --output_dir ${{outputs.model_output}}\",\n",
        "    environment=donut_env,\n",
        "    compute=\"anishswiss1\",\n",
        "    display_name=\"donut-lora-train\",\n",
        "    experiment_name=\"donut-lora-exp\",\n",
        "    outputs={\n",
        "        \"model_output\": Output(type=\"uri_folder\", mode=\"upload\")\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "# Submit\n",
        "returned_job = ml_client.jobs.create_or_update(job)\n",
        "print(f\"Submitted job: {returned_job.name}\")\n",
        "\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\nOverriding of current TracerProvider is not allowed\nOverriding of current LoggerProvider is not allowed\nOverriding of current MeterProvider is not allowed\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nWarning: the provided asset name 'donut-lora-env' will not be used for anonymous registration\nWarning: the provided asset name 'donut-lora-env' will not be used for anonymous registration\npathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Submitted job: patient_zebra_hlpm8t7gt2\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1763834308151
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torch torchvision torchaudio\n",
        "\n",
        "\n",
        "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "download_path = \"./donut_qa_model\"\n",
        "\n",
        "\n",
        "model_folder = os.path.join(download_path, \"donutQA/outputs/donut-lora\")  # may need adjustment\n",
        "\n",
        "files_only = [f for f in os.listdir(model_folder) if os.path.isfile(os.path.join(model_folder, f))]\n",
        "print(\"FILES .... \")\n",
        "print(files_only)\n",
        "\n",
        "processor = DonutProcessor.from_pretrained(model_folder)\n",
        "model = VisionEncoderDecoderModel.from_pretrained(model_folder)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: torch in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (2.8.0)\nRequirement already satisfied: torchvision in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (0.23.0)\nRequirement already satisfied: torchaudio in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (2.8.0)\nRequirement already satisfied: filelock in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (4.14.1)\nRequirement already satisfied: sympy>=1.13.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (1.14.0)\nRequirement already satisfied: networkx in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (2023.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (12.8.93)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (12.8.90)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (12.8.90)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (12.8.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (11.3.3.83)\nRequirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (10.3.9.90)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (11.7.3.90)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (12.5.8.93)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (12.8.90)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (12.8.93)\nRequirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (1.13.1.3)\nRequirement already satisfied: triton==3.4.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (3.4.0)\nRequirement already satisfied: setuptools>=40.8.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from triton==3.4.0->torch) (78.1.1)\nRequirement already satisfied: numpy in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torchvision) (1.23.5)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torchvision) (11.3.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/anaconda/envs/azureml_py310_sdkv2/bin/python -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\nFILES .... \n['.amlignore', '.amlignore.amltmp', 'added_tokens.json', 'config.json', 'generation_config.json', 'model.safetensors', 'preprocessor_config.json', 'sentencepiece.bpe.model', 'special_tokens_map.json', 'tokenizer.json', 'tokenizer_config.json']\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\nUsing a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1763851714417
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = Image.open(\"test_pay_stub.jpg\").convert(\"RGB\")\n",
        "question = \"What is the net pay?\"\n",
        "\n",
        "prompt = f\"<s_docvqa><s_question>{question}</s_question><s_answer>\"\n"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1763854135455
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare inputs\n",
        "pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
        "decoder_input_ids = processor.tokenizer(prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
        "\n",
        "# Generate prediction\n",
        "outputs = model.generate(\n",
        "    pixel_values,\n",
        "    decoder_input_ids=decoder_input_ids,\n",
        "    max_length=model.decoder.config.max_position_embeddings,\n",
        "    early_stopping=True,\n",
        "    pad_token_id=processor.tokenizer.pad_token_id,\n",
        "    eos_token_id=processor.tokenizer.eos_token_id,\n",
        "    use_cache=True,\n",
        "    bad_words_ids=[[processor.tokenizer.unk_token_id]],\n",
        "    return_dict_in_generate=True,\n",
        ")\n",
        "\n",
        "# Decode answer\n",
        "sequence = processor.batch_decode(outputs.sequences)[0]\n",
        "answer = sequence.split(\"<s_answer>\")[1].split(\"</s_answer>\")[0]\n",
        "\n",
        "print(f\"Predicted answer: {answer}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Predicted answer:  $853.30\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1763854168466
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#conda env update -f environment.yaml\n",
        "\n",
        "import sys\n",
        "print(sys.executable)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/anaconda/envs/azureml_py38/bin/python\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1763990350725
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deploy the model to a managed online endpoint\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml.entities import ManagedOnlineEndpoint, ManagedOnlineDeployment, Environment\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from datetime import datetime\n",
        "\n",
        "# Create ml_client if it doesn't exist (from Cell 1)\n",
        "if 'ml_client' not in globals():\n",
        "    print(\"Creating MLClient connection...\")\n",
        "    ml_client = MLClient.from_config(DefaultAzureCredential())\n",
        "\n",
        "# Get or create donut_env if it doesn't exist\n",
        "if 'donut_env' not in globals():\n",
        "    print(\"Creating environment definition...\")\n",
        "    donut_env = Environment(\n",
        "        name=\"donut-lora-env\",\n",
        "        image=\"mcr.microsoft.com/azureml/curated/acpt-pytorch-2.0-cuda11.7:latest\",\n",
        "        conda_file=\"environment.yaml\"\n",
        "    )\n",
        "    # Register it\n",
        "    ml_client.environments.create_or_update(donut_env)\n",
        "\n",
        "# Get the registered environment with specific version\n",
        "# Use version 23 (or get the latest if you prefer)\n",
        "env_version = 23  # Specify the version number\n",
        "try:\n",
        "    registered_env = ml_client.environments.get(donut_env.name, version=str(env_version))\n",
        "    env_ref = registered_env\n",
        "    print(f\"Using registered environment: {registered_env.name}:{registered_env.version}\")\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Could not get environment version {env_version}. Error: {e}\")\n",
        "    # Fallback: use string format \"name:version\"\n",
        "    env_ref = f\"{donut_env.name}:{env_version}\"\n",
        "    print(f\"Using environment reference: {env_ref}\")\n",
        "\n",
        "# Create endpoint\n",
        "endpoint_name = f\"donutqa-endpoint-{datetime.now().strftime('%m%d%H%M')}\"\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=endpoint_name,\n",
        "    auth_mode=\"key\"\n",
        ")\n",
        "ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
        "print(f\"Created endpoint: {endpoint_name}\")\n",
        "\n",
        "# Deploy model\n",
        "deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue\",\n",
        "    endpoint_name=endpoint_name,\n",
        "    model=\"donutQA:1\",  # String reference to registered model\n",
        "    environment=env_ref,  # Use registered environment object\n",
        "    code_path=\"src\",\n",
        "    scoring_script=\"score.py\",  # Use scoring_script instead of entry_script\n",
        "    instance_type=\"Standard_E4s_v3\",\n",
        "    instance_count=1\n",
        ")\n",
        "ml_client.online_deployments.begin_create_or_update(deployment).result()\n",
        "print(\"Deployment created successfully\")\n",
        "\n",
        "# Route traffic\n",
        "endpoint.traffic = {\"blue\": 100}\n",
        "ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
        "print(\"Traffic routed to deployment\")\n",
        "\n",
        "# Get endpoint details\n",
        "endpoint = ml_client.online_endpoints.get(endpoint_name)\n",
        "print(f\"\\nâœ… Endpoint deployed successfully!\")\n",
        "print(f\"Endpoint name: {endpoint_name}\")\n",
        "print(f\"Scoring URI: {endpoint.scoring_uri}\")\n",
        "print(f\"Status: {endpoint.provisioning_state}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Creating MLClient connection...\nCreating environment definition...\nUsing registered environment: donut-lora-env:23\nCreated endpoint: donutqa-endpoint-11271214\n......................................................................................................................................................."
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/__init__.py:41: UserWarning: Versions of mlflow (3.1.1) and mlflow-skinny (2.22.1) are different. This may lead to unexpected behavior. Please install the same version of both packages.\n  mlflow.mismatch._check_version_mismatch()\nCheck: endpoint donutqa-endpoint-11271214 exists\n"
        },
        {
          "output_type": "error",
          "ename": "HttpResponseError",
          "evalue": "(BadArgument) User container has crashed or terminated. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-resourcenotready\nCode: BadArgument\nMessage: User container has crashed or terminated. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-resourcenotready",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOperationFailed\u001b[0m                           Traceback (most recent call last)",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/polling/base_polling.py:805\u001b[0m, in \u001b[0;36mLROBasePolling.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 805\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m BadStatus \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/polling/base_polling.py:837\u001b[0m, in \u001b[0;36mLROBasePolling._poll\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _failed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus()):\n\u001b[0;32m--> 837\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OperationFailed(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOperation failed or canceled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    839\u001b[0m final_get_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operation\u001b[38;5;241m.\u001b[39mget_final_get_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipeline_response)\n",
            "\u001b[0;31mOperationFailed\u001b[0m: Operation failed or canceled",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 56\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Deploy model\u001b[39;00m\n\u001b[1;32m     46\u001b[0m deployment \u001b[38;5;241m=\u001b[39m ManagedOnlineDeployment(\n\u001b[1;32m     47\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     48\u001b[0m     endpoint_name\u001b[38;5;241m=\u001b[39mendpoint_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m     instance_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     55\u001b[0m )\n\u001b[0;32m---> 56\u001b[0m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monline_deployments\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin_create_or_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeployment\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeployment created successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Route traffic\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/polling/_poller.py:326\u001b[0m, in \u001b[0;36mLROPoller.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PollingReturnType_co:\n\u001b[1;32m    318\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the result of the long running operation, or\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;124;03m    the result available after the specified timeout.\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m    :raises ~azure.core.exceptions.HttpResponseError: Server problem with the query.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_polling_method\u001b[38;5;241m.\u001b[39mresource()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/tracing/decorator.py:119\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# If tracing is disabled globally and user didn't explicitly enable it, don't trace.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m tracing_enabled \u001b[38;5;129;01mand\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/polling/_poller.py:345\u001b[0m, in \u001b[0;36mLROPoller.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thread\u001b[38;5;241m.\u001b[39mjoin(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;66;03m# Let's handle possible None in forgiveness here\u001b[39;00m\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;66;03m# https://github.com/python/mypy/issues/8165\u001b[39;00m\n\u001b[0;32m--> 345\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# Was None\u001b[39;00m\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/polling/_poller.py:250\u001b[0m, in \u001b[0;36mLROPoller._start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Start the long running operation.\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03mOn completion, runs any callbacks.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_polling_method\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m AzureError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m error\u001b[38;5;241m.\u001b[39mcontinuation_token:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/polling/base_polling.py:820\u001b[0m, in \u001b[0;36mLROBasePolling.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(\n\u001b[1;32m    814\u001b[0m         response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipeline_response\u001b[38;5;241m.\u001b[39mhttp_response,\n\u001b[1;32m    815\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(err),\n\u001b[1;32m    816\u001b[0m         error\u001b[38;5;241m=\u001b[39merr,\n\u001b[1;32m    817\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OperationFailed \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 820\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipeline_response\u001b[38;5;241m.\u001b[39mhttp_response, error\u001b[38;5;241m=\u001b[39merr) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n",
            "\u001b[0;31mHttpResponseError\u001b[0m: (BadArgument) User container has crashed or terminated. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-resourcenotready\nCode: BadArgument\nMessage: User container has crashed or terminated. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-resourcenotready"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1764246538494
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.18",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}