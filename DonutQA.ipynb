{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1763834308151
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found the config file in: /config.json\n",
            "Overriding of current TracerProvider is not allowed\n",
            "Overriding of current LoggerProvider is not allowed\n",
            "Overriding of current MeterProvider is not allowed\n",
            "Attempting to instrument while already instrumented\n",
            "Attempting to instrument while already instrumented\n",
            "Attempting to instrument while already instrumented\n",
            "Attempting to instrument while already instrumented\n",
            "Attempting to instrument while already instrumented\n",
            "Warning: the provided asset name 'donut-lora-env' will not be used for anonymous registration\n",
            "Warning: the provided asset name 'donut-lora-env' will not be used for anonymous registration\n",
            "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submitted job: patient_zebra_hlpm8t7gt2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from azure.ai.ml import MLClient, command, Output\n",
        "from azure.ai.ml.entities import Environment\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "\n",
        "# Connect to AML workspace\n",
        "ml_client = MLClient.from_config(DefaultAzureCredential())\n",
        "\n",
        "\n",
        "# Define environment\n",
        "donut_env = Environment(\n",
        "    name=\"donut-lora-env\",\n",
        "    image=\"mcr.microsoft.com/azureml/curated/acpt-pytorch-2.0-cuda11.7:latest\",\n",
        "    conda_file=\"environment.yaml\"\n",
        ")\n",
        "\n",
        "# Register environment\n",
        "ml_client.environments.create_or_update(donut_env)\n",
        "\n",
        "\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python train.py --data_dir ./data --output_dir ${{outputs.model_output}}\",\n",
        "    environment=donut_env,\n",
        "    compute=\"anishswiss1\",\n",
        "    display_name=\"donut-lora-train\",\n",
        "    experiment_name=\"donut-lora-exp\",\n",
        "    outputs={\n",
        "        \"model_output\": Output(type=\"uri_folder\", mode=\"upload\")\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "# Submit\n",
        "returned_job = ml_client.jobs.create_or_update(job)\n",
        "print(f\"Submitted job: {returned_job.name}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1763851714417
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (2.8.0)\n",
            "Requirement already satisfied: torchvision in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (0.23.0)\n",
            "Requirement already satisfied: torchaudio in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (2.8.0)\n",
            "Requirement already satisfied: filelock in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (2023.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.4.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from triton==3.4.0->torch) (78.1.1)\n",
            "Requirement already satisfied: numpy in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/anaconda/envs/azureml_py310_sdkv2/bin/python -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "FILES .... \n",
            "['.amlignore', '.amlignore.amltmp', 'added_tokens.json', 'config.json', 'generation_config.json', 'model.safetensors', 'preprocessor_config.json', 'sentencepiece.bpe.model', 'special_tokens_map.json', 'tokenizer.json', 'tokenizer_config.json']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        }
      ],
      "source": [
        "%pip install torch torchvision torchaudio\n",
        "\n",
        "\n",
        "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "download_path = \"./donut_qa_model\"\n",
        "\n",
        "\n",
        "model_folder = os.path.join(download_path, \"donutQA/outputs/donut-lora\")  # may need adjustment\n",
        "\n",
        "files_only = [f for f in os.listdir(model_folder) if os.path.isfile(os.path.join(model_folder, f))]\n",
        "print(\"FILES .... \")\n",
        "print(files_only)\n",
        "\n",
        "processor = DonutProcessor.from_pretrained(model_folder)\n",
        "model = VisionEncoderDecoderModel.from_pretrained(model_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1763854135455
        }
      },
      "outputs": [],
      "source": [
        "image = Image.open(\"test_pay_stub.jpg\").convert(\"RGB\")\n",
        "question = \"What is the net pay?\"\n",
        "\n",
        "prompt = f\"<s_docvqa><s_question>{question}</s_question><s_answer>\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1763854168466
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted answer:  $853.30\n"
          ]
        }
      ],
      "source": [
        "# Prepare inputs\n",
        "pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
        "decoder_input_ids = processor.tokenizer(prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
        "\n",
        "# Generate prediction\n",
        "outputs = model.generate(\n",
        "    pixel_values,\n",
        "    decoder_input_ids=decoder_input_ids,\n",
        "    max_length=model.decoder.config.max_position_embeddings,\n",
        "    early_stopping=True,\n",
        "    pad_token_id=processor.tokenizer.pad_token_id,\n",
        "    eos_token_id=processor.tokenizer.eos_token_id,\n",
        "    use_cache=True,\n",
        "    bad_words_ids=[[processor.tokenizer.unk_token_id]],\n",
        "    return_dict_in_generate=True,\n",
        ")\n",
        "\n",
        "# Decode answer\n",
        "sequence = processor.batch_decode(outputs.sequences)[0]\n",
        "answer = sequence.split(\"<s_answer>\")[1].split(\"</s_answer>\")[0]\n",
        "\n",
        "print(f\"Predicted answer: {answer}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1763990350725
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/azureml_py38/bin/python\n"
          ]
        }
      ],
      "source": [
        "#conda env update -f environment.yaml\n",
        "\n",
        "import sys\n",
        "print(sys.executable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1764282886440
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using registered environment: donut-lora-env:23\n",
            "Created endpoint: donutqa-endpoint-11272217\n",
            "..........................................................................................................................................................................Deployment created successfully\n",
            "Traffic routed to deployment\n",
            "\n",
            "✅ Endpoint deployed successfully!\n",
            "Endpoint name: donutqa-endpoint-11272217\n",
            "Scoring URI: https://donutqa-endpoint-11272217.eastus2.inference.ml.azure.com/score\n",
            "Status: Succeeded\n"
          ]
        }
      ],
      "source": [
        "# Deploy the model to a managed online endpoint\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml.entities import ManagedOnlineEndpoint, ManagedOnlineDeployment, Environment, OnlineRequestSettings\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "# Create ml_client if it doesn't exist (from Cell 1)\n",
        "if 'ml_client' not in globals():\n",
        "    print(\"Creating MLClient connection...\")\n",
        "    ml_client = MLClient.from_config(DefaultAzureCredential())\n",
        "\n",
        "# Get or create donut_env if it doesn't exist\n",
        "if 'donut_env' not in globals():\n",
        "    print(\"Creating environment definition...\")\n",
        "    donut_env = Environment(\n",
        "        name=\"donut-lora-env\",\n",
        "        image=\"mcr.microsoft.com/azureml/curated/acpt-pytorch-2.0-cuda11.7:latest\",\n",
        "        conda_file=\"environment.yaml\"\n",
        "    )\n",
        "    # Register it\n",
        "    ml_client.environments.create_or_update(donut_env)\n",
        "\n",
        "# Get the registered environment with specific version\n",
        "# Use version 23 (or get the latest if you prefer)\n",
        "env_version = 23  # Specify the version number\n",
        "try:\n",
        "    registered_env = ml_client.environments.get(donut_env.name, version=str(env_version))\n",
        "    env_ref = registered_env\n",
        "    print(f\"Using registered environment: {registered_env.name}:{registered_env.version}\")\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Could not get environment version {env_version}. Error: {e}\")\n",
        "    # Fallback: use string format \"name:version\"\n",
        "    env_ref = f\"{donut_env.name}:{env_version}\"\n",
        "    print(f\"Using environment reference: {env_ref}\")\n",
        "\n",
        "# Use a fixed endpoint name for consistency\n",
        "# This will create the endpoint if it doesn't exist, or update it if it does\n",
        "endpoint_name = \"document-qa-endpoint\"\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=endpoint_name,\n",
        "    auth_mode=\"key\"\n",
        ")\n",
        "ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
        "print(f\"Endpoint '{endpoint_name}' ready (created or updated)\")\n",
        "\n",
        "request_settings = OnlineRequestSettings(\n",
        "    request_timeout_ms=180000   # 180 seconds (3min)\n",
        ")\n",
        "\n",
        "# Deploy model\n",
        "deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue\",\n",
        "    endpoint_name=endpoint_name,\n",
        "    model=\"donutQA:1\",  # String reference to registered model\n",
        "    environment=env_ref,  # Use registered environment object\n",
        "    code_path=\"src\",\n",
        "    scoring_script=\"score.py\",  # Use scoring_script instead of entry_script\n",
        "    instance_type=\"Standard_E4s_v3\",\n",
        "    instance_count=1,\n",
        "    request_settings=request_settings \n",
        ")\n",
        "ml_client.online_deployments.begin_create_or_update(deployment).result()\n",
        "print(\"Deployment created successfully\")\n",
        "\n",
        "\n",
        "# Route traffic\n",
        "endpoint.traffic = {\"blue\": 100}\n",
        "ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
        "print(\"Traffic routed to deployment\")\n",
        "\n",
        "# Get endpoint details\n",
        "endpoint = ml_client.online_endpoints.get(endpoint_name)\n",
        "print(f\"\\n✅ Endpoint deployed successfully!\")\n",
        "print(f\"Endpoint name: {endpoint_name}\")\n",
        "print(f\"Scoring URI: {endpoint.scoring_uri}\")\n",
        "print(f\"Status: {endpoint.provisioning_state}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
